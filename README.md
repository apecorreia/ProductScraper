# ğŸ› ï¸ ProductScraper 

![https://img.shields.io/badge/License-MIT-yellow.svg](./LICENSE)

**ProductScraper** is a scalable web scraping framework designed to collect, clean, and store product data from multiple Portuguese supermarkets (e.g., **Continente, Pingo Doce, Auchan**).  
It powers downstream applications like **SmartCart**, enabling real-time price comparison and optimized shopping lists.

--- 

## ğŸ”¥ FEATURES 
- **Multi-Site Scraping** 
  - Scrapy spiders for HTML and JSON-based APIs
  - Splash integration for JavaScript-heavy sites
- **Database Integration**
  - PostgreSQL & SQLite support with SQLAlchemy ORM
  - Automatic database versioning with timestamps
  - Deduplication logic to avoid duplicate entries
- **Scalability & Performance**
  - Batch commits of 1000 items
  - Proxy/IP rotation (Bright Data) to bypass restrictions
  - Daily scraping limits with JSON-based progress tracking
- **Data Collected**
  - Product name, brand, category
  - Quantity & packaging
  - Prices (primary & secondary units)
  - Image links
    
--- 

## ğŸ“ TECH STACK 
  
  - **Language:** Python 3.11+ 
  - **Frameworks & Libraries:** Scrapy, SQLAlchemy, Flask 
  - **Database:** PostgreSQL / SQLite 
  - **Tools:** Splash (for dynamic pages), Bright Data (proxy rotation), JSON 

--- 

## ğŸ“‚ PROJECT STRUCTURE 

```bash
ProductScraper/
â”œâ”€â”€ configuration/
â”‚ â”œâ”€â”€ base.py # Base object initialization
â”‚ â””â”€â”€ connection.py # Database connection handler
â”‚
â”œâ”€â”€ entities/ # Project models
â”‚ â”œâ”€â”€ db_registry.py
â”‚ â””â”€â”€ product.py # SQLAlchemy models for product tables
â”‚
â”œâ”€â”€ scraper/
â”‚ â”œâ”€â”€ spiders/ # Scrapy spiders for each store
â”‚ â”‚ â”œâ”€â”€ continente_spider.py
â”‚ â”‚ â”œâ”€â”€ pingo_doce_spider.py
â”‚ â”‚ â”œâ”€â”€ auchan_spider.py
â”‚ â”‚ â””â”€â”€ spiders_progress.py # Spiders progress handler
â”‚ â”œâ”€â”€ items.py # ProductItem definition
â”‚ â”œâ”€â”€ middlewares.py # Middleware (incl. fake user-agent)
â”‚ â”œâ”€â”€ pipelines/ # Data pipelines (deduplication, batching, DB commits)
â”‚ â””â”€â”€ settings.py # Scrapy settings
â”‚
â”œâ”€â”€ utilities/ # Helper functions & post-processing tools
â”‚ â”œâ”€â”€ csv/
â”‚ â”‚ â”œâ”€â”€ brands.csv
â”‚ â”‚ â”œâ”€â”€ products.csv
â”‚ â”‚ â””â”€â”€ products_cleaned.csv
â”‚ â”œâ”€â”€ json/
â”‚ â”‚ â”œâ”€â”€ category_mapping.json
â”‚ â”‚ â””â”€â”€ continente_categories.json
â”‚ â”œâ”€â”€ txt/
â”‚ â”‚ â”œâ”€â”€ category_inconsistencies.txt
â”‚ â”‚ â””â”€â”€ skipped_products.txt
â”‚ â”œâ”€â”€ category_normalizer.py # Category normalization across stores
â”‚ â”œâ”€â”€ data_manager.py # Data processing tools
â”‚ â”œâ”€â”€ db_manager.py # Database handling tools
â”‚ â””â”€â”€ qnt_brand_extraction.py# Quantity & brand extraction
â”‚
â”œâ”€â”€ app.py # Entry point for running spiders
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ scrapy.cfg # Scrapy configuration
â””â”€â”€ README.md
```

---

# âš¡INSTALATION

1. Clone the repository:
   ```bash
   git clone https://github.com/apecorreia/ProductScraper.git
   cd ProductScraper
   ```

2. Create a virtual environment and install dependencies:
    ```bash
    python -m venv venv
    source venv/bin/activate   # On Windows: venv\Scripts\activate
    pip install -r requirements.txt
    ```

4. Configure database (PostgreSQL or SQLite) in settings.py:
    ```bash
    DATABASE_URL = "postgresql://user:password@localhost:5432/product_scraper"
    ```
  ### or SQLite example:
  
  ```bash
    DATABASE_URL = "sqlite:///path_to_db/database.db"
  ```
---

## â–¶ï¸ USAGE
- Run a specific spider:
    ```bash
    scrapy crawl continente_spider
    scrapy crawl pingo_doce_spider
    scrapy crawl auchan_spider
    ```

  ### OR

- Run all spiders at once
    ```bash
    python app.py
    ```

### ğŸ“Š Example Output
| id | store       | category  | sub_category   | name               | brand | quantity | primary_price | secondary_price | img_lnk                                                        |
| -- | ----------- | --------- | -------------- |------------------- | ----- | -------- | -------------- | ---------------- | ------------------------------------------------------------ |
| 1  | continente  | Bebidas   | Ãguas          | Ãgua Mineral 1.5L  | Luso  | 1.5L     | â‚¬0.89          | â‚¬0.59/L          | [https://.../images/luso.jpg](https://.../images/luso.jpg)   |
| 2  | pingo\_doce | Mercearia | Arroz e Massas | Arroz Carolino 1kg | Pingo | 1kg      | â‚¬1.25          | â‚¬1.25/kg         | [https://.../images/arroz.jpg](https://.../images/arroz.jpg) |


NOTE: Each execution has a default limit of 10 categories per scrape process.
This can be adjusted in settings.py, but increasing it too much may result in IP bans.


---


ğŸ‘¨â€ğŸ’» Author

Developed by AntÃ³nio Correia
ğŸ“© Contact: [Linkedin Profile](https://www.linkedin.com/in/antÃ³nio-correia-4013242b7)
 â€¢ Email: antoniocorreia0708@gmail.com
